{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyemd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk import tokenize    \n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "    \n",
    "def parse(text):\n",
    "    words = []\n",
    "    word_pattern = rpt(r'\\w+')\n",
    "    \n",
    "    patterns = [word_pattern]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(text):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token.lower())\n",
    "        words.extend(tokens)\n",
    "    return words\n",
    "\n",
    "### carregando modelo pré-treinado e nomalizando-o\n",
    "model = KeyedVectors.load_word2vec_format(\"wiki_vectors_format_without_stopwords.bin\", binary=False)\n",
    "model.init_sims(replace=True) \n",
    "\n",
    "def headline_embeddings(headline):\n",
    "    emb = []\n",
    "    for word in headline:\n",
    "        emb.append(model[word])\n",
    "    return emb\n",
    "        \n",
    "headline = \"O que Bolsonaro e Moro colocam em jogo\"\n",
    "headline = parse(headline)\n",
    "hl_e1 = headline_embeddings(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 10 first for the first word: [-0.06797549  0.0969245  -0.0308466  -0.07459277 -0.01058708 -0.04934659\n",
      "  0.08344505 -0.08326908  0.09534609  0.02884346]\n",
      "Embedding lenght: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding 10 first for the first word:\", hl_e1[0][:10])\n",
    "print(\"Embedding lenght:\", len(hl_e1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acima temos um exemplo dos 10 primeiros vetores para a primeira palavra analisada e o tamanho total do embedding para a headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3747184760019384\n",
      "1.3814151057415365\n"
     ]
    }
   ],
   "source": [
    "headline2 = \"Os prejuizos da Operacao Lava Jato para o Brasil\"\n",
    "headline2 = parse(headline2)\n",
    "hl_e2 = headline_embeddings(headline2)\n",
    "\n",
    "from math import inf\n",
    "from math import sqrt\n",
    "\n",
    "def calc_wmd(vector1, vector2):\n",
    "    wmd = 0     \n",
    "    for w in vector1:\n",
    "        min_dist = inf\n",
    "        for w2 in vector2:\n",
    "            min_dist = min(min_dist, sqrt(sum((w - w2) ** 2)))\n",
    "        wmd += min_dist * 1.0/len(vector1) ### normaliza score pelas palavras movidas        \n",
    "    return wmd\n",
    "\n",
    "calc_wmd(hl_e1, hl_e2)\n",
    "model.wmdistance(headline, headline2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vemos acima que o método implementado se aproxima ao método wmdistance que é implementado pela biblioteca gensim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implemente uma função que possa receber qualquer notícia como entrada e retornar as top-3 notícias mais similares (menos distantes) a ela (35 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bolsonaro e Trump reforcam lacos diplomaticos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1 - Similaridade = 0.4720 - O que Bolsonaro e Moro colocam em jogo',\n",
       " '2 - Similaridade = 0.4243 - Mitos e verdades sobre o consumo de pimenta para a saude',\n",
       " '3 - Similaridade = 0.4236 - Lava Jato desconfiava de Leo Pinheiro ate versao do triplex do Guaruja']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\"Selecao brasileira joga proxima terca-feira\",\n",
    "        \"Neymar é acusado de estupro\",\n",
    "        \"Mitos e verdades sobre o consumo de pimenta para a saude\",\n",
    "        \"Saiba qual é o tecido que os gatos mais gostam de arranhar\",\n",
    "        \"Lava Jato desconfiava de Leo Pinheiro ate versao do triplex do Guaruja\",\n",
    "        \"China e EUA concordam em retomar negociacoes comerciais\",\n",
    "        \"As gambiarras que todo jogador ja fez na vida\",\n",
    "        \"O seda em fim de ciclo com vendas absurdas\",\n",
    "        \"Os prejuizos da Operacao Lava Jato para o Brasil\",\n",
    "        \"O que Bolsonaro e Moro colocam em jogo\"]\n",
    "\n",
    "query = \"Bolsonaro e Trump reforcam lacos diplomaticos\"\n",
    "\n",
    "from gensim.similarities import WmdSimilarity\n",
    "\n",
    "def topN_sim_docs(query, docs, N):\n",
    "    top = []\n",
    "    num_best = N\n",
    "    processed_docs = [parse(w) for w in docs]\n",
    "    instance = WmdSimilarity(processed_docs, model, num_best)\n",
    "    \n",
    "    p_query = parse(query)\n",
    "    rank = instance[p_query]\n",
    "\n",
    "    for i in range(num_best):\n",
    "        top.append('%d - Similaridade = %.4f - %s' % (i+1,rank[i][1], docs[rank[i][0]]))\n",
    "        \n",
    "    return top\n",
    "\n",
    "print(query)\n",
    "topN_sim_docs(query, docs, N=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencias \n",
    "[1]https://docs.google.com/presentation/d/1CTmpRHA2gurNM6APTpXzmpfVSZLgRoOszA3XQ-PyCto/edit#slide=id.gc6f73a04f_0_0\n",
    "[2]https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
