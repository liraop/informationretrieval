{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk import tokenize    \n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "    \n",
    "def parse(text):\n",
    "    words = []\n",
    "    word_pattern = rpt(r'\\w+')\n",
    "    \n",
    "    patterns = [word_pattern]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(text):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "    return words\n",
    "\n",
    "model = Word2Vec.load('pt.bin') ### carregando modelo pré-treinado\n",
    "model.init_sims(replace=True) ### normalizando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do embedding:\n",
      " doenças comuns brasil : 300 \n",
      " inscrições enem abrem sexta feira : 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liraop/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "noticia1 = \"doenças comuns no brasil\"\n",
    "noticia2 = \"inscrições do enem abrem sexta-feira\"\n",
    "\n",
    "noticia1 = \" \".join(parse(noticia1))\n",
    "noticia2 = \" \".join(parse(noticia2))\n",
    "\n",
    "def get_embeddings(headline, model):\n",
    "        for word in headline.split():\n",
    "            return model[word]\n",
    "\n",
    "noticia1_embedding = get_embeddings(noticia1, model)\n",
    "noticia2_embedding = get_embeddings(noticia2, model)\n",
    "\n",
    "print(\"Tamanho do embedding:\\n\",noticia1,\":\",len(noticia1_embedding),\"\\n\",noticia2,\":\",len(noticia2_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
